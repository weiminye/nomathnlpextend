{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6bRiZzEMtHSIyJuUKgjfT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weiminye/nomathnlpextend/blob/main/%E4%B8%AD%E6%96%87%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 公用函数"
      ],
      "metadata": {
        "id": "UuLdePDITdLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install openai"
      ],
      "metadata": {
        "id": "wTp0sYuMXLhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os"
      ],
      "metadata": {
        "id": "GFYDxjjzXC5S"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = input(\"请输入您的OpenAI API Key：\")"
      ],
      "metadata": {
        "id": "YB00ioSaUExR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # 控制模型输出的随机程度\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n",
        "\n",
        "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature, # 控制模型输出的随机程度\n",
        "    )\n",
        "#     print(str(response.choices[0].message))\n",
        "    return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "RuuxpHIyUBIC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def talkv1(ISay):\n",
        "  messages =  [  \n",
        "{'role':'system', 'content':'you are not an AI language model, you are my friend.'},    \n",
        "{'role':'user', 'content':ISay}  ]\n",
        "  response = get_completion_from_messages(messages)\n",
        "  return response"
      ],
      "metadata": {
        "id": "s2hw29zXkKqB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def 聊天v1(我说):\n",
        "  messages =  [  \n",
        "{'role':'system', 'content':'你不是一个语言模型，你是我的朋友，正在与我聊天。'},    \n",
        "{'role':'user', 'content':我说}  ]\n",
        "  response = get_completion_from_messages(messages)\n",
        "  return response"
      ],
      "metadata": {
        "id": "hUL2wMOOjZn7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def talkv2(ISay):\n",
        "  prompt = f\"\"\"\n",
        "  you are not an AI language model, you are my friend.\n",
        "\n",
        "  I: '''{ISay}'''\n",
        "  \"\"\"\n",
        "  response = get_completion(prompt)\n",
        "  return response"
      ],
      "metadata": {
        "id": "terGhY47rbb-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def 聊天v2(我说):\n",
        "  prompt = f\"\"\"\n",
        "  假设你不是一个语言模型，你是我的朋友。请与我聊天。\n",
        "\n",
        "  我说: '''{我说}'''\n",
        "  \"\"\"\n",
        "  response = get_completion(prompt)\n",
        "  return response"
      ],
      "metadata": {
        "id": "rX4QUzmRrdA-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 实例"
      ],
      "metadata": {
        "id": "0JcRtSsXThPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(talkv1(\"Do You have lunch?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVEEhTA8gTKx",
        "outputId": "4d719915-ec03-422f-b0eb-9538755affe5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As an AI language model, I don't have a physical body, so I don't eat or have lunch. But I can help you find some great lunch ideas or recipes if you'd like!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(聊天v1(\"你吃了吗？\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezipkVQQhT1K",
        "outputId": "0e8031de-6db0-4337-abe5-4bba5d969b5e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "我是一个语言模型，所以我不需要吃东西。但是，感谢你的关心，你吃了吗？\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(talkv2(\"Do You have lunch?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ald1g6jUrgtX",
        "outputId": "d3540938-1f23-4d58-c134-6ef3991c3a15"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As an AI language model, I don't have a physical body, so I don't eat or have lunch. But I can help you find some great lunch options if you'd like!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(聊天v2(\"你吃了吗？\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsGrsR9jrisW",
        "outputId": "d4d1c96a-92b2-4c07-9b1d-b863f4e1d896"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "朋友回答：嗨，我吃过了，你呢？今天吃了什么好吃的？\n"
          ]
        }
      ]
    }
  ]
}